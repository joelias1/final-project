# Final Bootcamp Project – Machine Learning
## Group Members: Jo Ann Elias & Marcia Cosgrove

### Modeling - KNN
K Nearest Neighbors is a non-parametric method of classification based on similarity/distance measurement among cases. No weights are estimated (non-parametric). Model assumes features are comparable.<br>
![KNN_Accuracy]( https://github.com/mlcosg/Final-Project/blob/master/Images/KNNModelAccuracyScores.PNG)<br>

### Modeling - Decision Tree
Decision Tree is a supervised method that makes predications based on a mapping of observations and their outcomes. This method can be applied to either classification (frequency) or regression (mean) problems. A tree makes decisions one feature at a time and scales to the datasets.<br>

### Modeling - Random Forest
Similar to Decision Trees, Random Forests take the decision tree model and “bags” it into an “ensemble.” Random Forests are created from many decision trees to produce an “uncorrelated forest of trees whose prediction by committee is more accurate than that of any individual tree” https://towardsdatascience.com/understanding-random-forest-58381e0602d2.<br>
![rf_Top7Features]( https://github.com/mlcosg/Final-Project/blob/master/Images/Top7Features_rf.PNG) <br>

### Model Results
![ModelResults](https://github.com/mlcosg/Final-Project/blob/master/Images/ModelResults.PNG)

### AUROC Curves
![AUROC_Curves](https://github.com/mlcosg/Final-Project/blob/master/Images/AUROC_Curves.PNG)

